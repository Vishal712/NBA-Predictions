{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vishalpatel/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/vishalpatel/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/vishalpatel/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/vishalpatel/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/vishalpatel/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/vishalpatel/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/vishalpatel/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/vishalpatel/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/vishalpatel/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/vishalpatel/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/vishalpatel/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/vishalpatel/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# import dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# set the seed value for the notebook so the results are reproducible\n",
    "from numpy.random import seed\n",
    "seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Player</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Age</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>MP</th>\n",
       "      <th>PER</th>\n",
       "      <th>USG%</th>\n",
       "      <th>WS</th>\n",
       "      <th>...</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "      <th>PPG</th>\n",
       "      <th>RPG</th>\n",
       "      <th>APG</th>\n",
       "      <th>SPG</th>\n",
       "      <th>BPG</th>\n",
       "      <th>NBA_PER_Range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>Mark Acres</td>\n",
       "      <td>C</td>\n",
       "      <td>27.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1691.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>9.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>362.0</td>\n",
       "      <td>4.525000</td>\n",
       "      <td>5.387500</td>\n",
       "      <td>0.837500</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>End of the Bench</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>Michael Adams</td>\n",
       "      <td>PG</td>\n",
       "      <td>27.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2690.0</td>\n",
       "      <td>15.4</td>\n",
       "      <td>18.5</td>\n",
       "      <td>6.9</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>1221.0</td>\n",
       "      <td>15.455696</td>\n",
       "      <td>2.848101</td>\n",
       "      <td>6.265823</td>\n",
       "      <td>1.531646</td>\n",
       "      <td>0.037975</td>\n",
       "      <td>Starter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>Mark Aguirre</td>\n",
       "      <td>SF</td>\n",
       "      <td>30.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>15.8</td>\n",
       "      <td>24.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>1099.0</td>\n",
       "      <td>14.089744</td>\n",
       "      <td>3.910256</td>\n",
       "      <td>1.858974</td>\n",
       "      <td>0.435897</td>\n",
       "      <td>0.243590</td>\n",
       "      <td>Starter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>Danny Ainge</td>\n",
       "      <td>PG</td>\n",
       "      <td>30.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2727.0</td>\n",
       "      <td>16.1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>1342.0</td>\n",
       "      <td>17.893333</td>\n",
       "      <td>4.346667</td>\n",
       "      <td>6.040000</td>\n",
       "      <td>1.506667</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>Starter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>Mark Alarie</td>\n",
       "      <td>PF</td>\n",
       "      <td>26.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1893.0</td>\n",
       "      <td>14.1</td>\n",
       "      <td>20.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>860.0</td>\n",
       "      <td>10.487805</td>\n",
       "      <td>4.560976</td>\n",
       "      <td>1.731707</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.475610</td>\n",
       "      <td>End of the Bench</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year         Player Pos   Age     G    GS      MP   PER  USG%   WS  ...  \\\n",
       "0  1990.0     Mark Acres   C  27.0  80.0  50.0  1691.0   8.3   9.4  1.6  ...   \n",
       "1  1990.0  Michael Adams  PG  27.0  79.0  74.0  2690.0  15.4  18.5  6.9  ...   \n",
       "2  1990.0   Mark Aguirre  SF  30.0  78.0  40.0  2005.0  15.8  24.3  5.7  ...   \n",
       "3  1990.0    Danny Ainge  PG  30.0  75.0  68.0  2727.0  16.1  23.0  4.8  ...   \n",
       "4  1990.0    Mark Alarie  PF  26.0  82.0  10.0  1893.0  14.1  20.4  3.1  ...   \n",
       "\n",
       "    BLK    TOV     PF     PTS        PPG       RPG       APG       SPG  \\\n",
       "0  25.0   70.0  248.0   362.0   4.525000  5.387500  0.837500  0.450000   \n",
       "1   3.0  141.0  133.0  1221.0  15.455696  2.848101  6.265823  1.531646   \n",
       "2  19.0  121.0  201.0  1099.0  14.089744  3.910256  1.858974  0.435897   \n",
       "3  18.0  185.0  238.0  1342.0  17.893333  4.346667  6.040000  1.506667   \n",
       "4  39.0  101.0  219.0   860.0  10.487805  4.560976  1.731707  0.731707   \n",
       "\n",
       "        BPG     NBA_PER_Range  \n",
       "0  0.312500  End of the Bench  \n",
       "1  0.037975           Starter  \n",
       "2  0.243590           Starter  \n",
       "3  0.240000           Starter  \n",
       "4  0.475610  End of the Bench  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in csv from S3 bucket\n",
    "cleaned_df = pd.read_csv(\"https://uci-dataproject3.s3-us-west-1.amazonaws.com/AllTimeNbaSeason4Categories1990.csv\")\n",
    "cleaned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign X (data) and y (target)\n",
    "X = cleaned_df[['PPG','APG','RPG','SPG','BPG','FG%','FT%','3P%']]\n",
    "\n",
    "X_names = X.columns\n",
    "\n",
    "y = cleaned_df['NBA_PER_Range'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a minmax scaler model and fit it to the training data\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/vishalpatel/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# create deep learning model and add layers\n",
    "deep_model = Sequential()\n",
    "deep_model.add(Dense(units=50, activation='relu', input_dim=8))\n",
    "deep_model.add(Dense(units=50, activation='relu'))\n",
    "deep_model.add(Dense(units=4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile and fit the model\n",
    "deep_model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                450       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 204       \n",
      "=================================================================\n",
      "Total params: 3,204\n",
      "Trainable params: 3,204\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# run a summary\n",
    "deep_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff5d03e0f10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "deep_model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=250,\n",
    "    shuffle=True,\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Learning Model - Model Loss: 0.38211523575652756, Model Accuracy: 0.8424223065376282\n"
     ]
    }
   ],
   "source": [
    "# examine loss and accuracy of deep learning\n",
    "model_loss, model_accuracy = deep_model.evaluate(\n",
    "    X_test_scaled, y_test_categorical, verbose=0)\n",
    "print(f\"Deep Learning Model - Model Loss: {model_loss}, Model Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Labels: ['End of the Bench' 'End of the Bench' 'End of the Bench'\n",
      " 'End of the Bench' 'All-Star']\n",
      "Actual Labels: ['End of the Bench', 'End of the Bench', 'End of the Bench', 'Starter', 'All-Star']\n"
     ]
    }
   ],
   "source": [
    "# show actual results versus the models prediction\n",
    "deep_predictions = deep_model.predict_classes(X_test_scaled[:5])\n",
    "deep_prediction_labels = label_encoder.inverse_transform(deep_predictions)\n",
    "print(f\"Predicted Labels: {deep_prediction_labels}\")\n",
    "print(f\"Actual Labels: {list(y_test[:5])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# received an error when using joblib, so used the saving model that was learned in the course for deep learning.\n",
    "deep_model.save(\"Deep_Learning_Model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
